<!DOCTYPE html>
<html lang="en-us">

<head>
    
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">
<meta name="referrer" content="origin">


<title>Research | PLAIA</title>
<meta name="description" content="PLAIA is a research group in the Boston University Center for Computing and Data Sciences. ">





    <link rel="shortcut icon" href="/icon_new.png">
    



<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link
    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,700;1,100;1,300;1,400;1,700&display=swap"
    rel="stylesheet">


<script src="https://kit.fontawesome.com/71dca6ca6a.js" crossorigin="anonymous"></script>


<link rel="stylesheet" href="/css/bootstrap.min.css">


<link rel="stylesheet" type="text/css" href="/css/style.css">
<link rel="stylesheet" type="text/css" href="/css/animations.css">



<meta property="og:title" content="Research" />
<meta property="og:description" content="PLAIA is a research group in the Boston University Center for Computing and Data Sciences." />
<meta property="og:type" content="website" />
<meta property="og:url" content="http://plaia.ai/research/" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Research"/>
<meta name="twitter:description" content="PLAIA is a research group in the Boston University Center for Computing and Data Sciences."/>


    


    

    
    
    
</head>

<body class="d-flex flex-column min-vh-100">
    


    <nav class="navbar navbar-expand-md navbar-light bg-light">
    <div class="container-md">
        <a href="/" class="navbar-brand">
            
            <img src="/site_logo_new.png" width=auto alt="PLAIA" style="max-width: 250px; max-height: 65px" />
            
            
            
        </a>
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#collapsableMenu">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="collapsableMenu">
            <ul class="navbar-nav nav-pills ms-auto">
                
                
                <li class="nav-item mb-2 mb-lg-0 mx-1"><a class="nav-link ps-2" href="/" title="Home">Home</a></li>
                

                
                
                
                <li class="nav-item mb-2 mb-lg-0 mx-1"><a class="nav-link ps-2" href="/members/" title="Members">Members</a></li>
                
                
                
                <li class="nav-item mb-2 mb-lg-0 mx-1"><a class="nav-link active ps-2" href="/research/"
                        title="Research">Research</a></li>
                
                
                
                <li class="nav-item mb-2 mb-lg-0 mx-1"><a class="nav-link ps-2" href="/join/" title="Join">Join</a></li>
                
                
            </ul>
        </div>
    </div>
</nav>




    <main>
        
        <div class="container-md">
        
<div class="section">
    <div class="content" id="tmp">
        <h1 class="page-title">Research</h1>

        
        <input type="radio" class="btn-check" name="topicRadio" id="All" autocomplete="off" checked>
        <label class="btn btn-outline-secondary me-2 mb-1" for="All">Show all</label>
        <div class="btn-group mb-1 d-inline-flex flex-wrap" id="topicForm">
        
                <input type="radio" class="btn-check" name="topicRadio" id="Statistical Learning Theory" autocomplete="off">
                <label class="btn btn-outline-secondary" for="Statistical Learning Theory">Statistical Learning Theory</label>
            
                <input type="radio" class="btn-check" name="topicRadio" id="Bandits" autocomplete="off">
                <label class="btn btn-outline-secondary" for="Bandits">Bandits</label>
            
                <input type="radio" class="btn-check" name="topicRadio" id="RLHF" autocomplete="off">
                <label class="btn btn-outline-secondary" for="RLHF">RLHF</label>
            
        </div>
        <div class="album mt-3" id="topicCards">
            
            
                <div class="card border-0 m-4 slide-fade-in" data-topics="[Statistical Learning Theory Bandits]">
    <div class="row row-cols-1 row-cols-md-2 d-flex align-items-center">
        <div class="col col-12 col-md-4 col-xl-3">
            
            <a href="https://arxiv.org/abs/2409.16197"><img src="secondorder.png" class="paper-img" width="100%" height="100%"
                    alt="Second Order Bounds for Contextual Bandits with Function Approximation" focusable="false" loading="lazy" /></a>
            
        </div>
        <div class="col col-12 col-md-8 col-xl-9 d-flex align-items-center">
            <div class="paper-body">
                <a href="https://arxiv.org/abs/2409.16197">
                    <h3 class="paper-title hover-underline-animation">Second Order Bounds for Contextual Bandits with Function Approximation</h3>
                </a>
                <p class="paper-authors">Aldo Pacchiano</p>
                <p class="paper-venue">ICLR 2025</p>
                
                
            </div>
        </div>
    </div>
    
</div>

            
                <div class="card border-0 m-4 slide-fade-in" data-topics="[Statistical Learning Theory Bandits Reinforcement Learning]">
    <div class="row row-cols-1 row-cols-md-2 d-flex align-items-center">
        <div class="col col-12 col-md-4 col-xl-3">
            
            <a href="https://arxiv.org/abs/2502.02516"><img src="adaptiveexplorationmulti.png" class="paper-img" width="100%" height="100%"
                    alt="Adaptive Exploration for Multi-Reward Multi-Policy Evaluation" focusable="false" loading="lazy" /></a>
            
        </div>
        <div class="col col-12 col-md-8 col-xl-9 d-flex align-items-center">
            <div class="paper-body">
                <a href="https://arxiv.org/abs/2502.02516">
                    <h3 class="paper-title hover-underline-animation">Adaptive Exploration for Multi-Reward Multi-Policy Evaluation</h3>
                </a>
                <p class="paper-authors">Alessio Russo, Aldo Pacchiano</p>
                <p class="paper-venue">arXiv</p>
                
                
            </div>
        </div>
    </div>
    
</div>

            
                <div class="card border-0 m-4 slide-fade-in" data-topics="[Statistical Learning Theory Bandits]">
    <div class="row row-cols-1 row-cols-md-2 d-flex align-items-center">
        <div class="col col-12 col-md-4 col-xl-3">
            
            <a href=""><img src="pureexplorationfeedback.png" class="paper-img" width="100%" height="100%"
                    alt="Pure Exploration with Feedback Graphs" focusable="false" loading="lazy" /></a>
            
        </div>
        <div class="col col-12 col-md-8 col-xl-9 d-flex align-items-center">
            <div class="paper-body">
                <a href="">
                    <h3 class="paper-title hover-underline-animation">Pure Exploration with Feedback Graphs</h3>
                </a>
                <p class="paper-authors">Alessio Russo, Yichen Song, Aldo Pacchiano</p>
                <p class="paper-venue">AISTATS 2025</p>
                
                
            </div>
        </div>
    </div>
    
</div>

            
                <div class="card border-0 m-4 slide-fade-in" data-topics="[Reinforcement Learning]">
    <div class="row row-cols-1 row-cols-md-2 d-flex align-items-center">
        <div class="col col-12 col-md-4 col-xl-3">
            
            <a href="https://arxiv.org/pdf/2408.04046"><img src="learningratefree.png" class="paper-img" width="100%" height="100%"
                    alt="Learning Rate-Free Reinforcement Learning: A Case for Model Selection with Non-Stationary Objectives" focusable="false" loading="lazy" /></a>
            
        </div>
        <div class="col col-12 col-md-8 col-xl-9 d-flex align-items-center">
            <div class="paper-body">
                <a href="https://arxiv.org/pdf/2408.04046">
                    <h3 class="paper-title hover-underline-animation">Learning Rate-Free Reinforcement Learning: A Case for Model Selection with Non-Stationary Objectives</h3>
                </a>
                <p class="paper-authors">Aida Afshar, Aldo Pacchiano</p>
                <p class="paper-venue">ArXiv</p>
                
                
            </div>
        </div>
    </div>
    
</div>

            
                <div class="card border-0 m-4 slide-fade-in" data-topics="[Reinforcement Learning Bandits RLHF]">
    <div class="row row-cols-1 row-cols-md-2 d-flex align-items-center">
        <div class="col col-12 col-md-4 col-xl-3">
            
            <a href="https://arxiv.org/abs/2402.10500"><img src="activepreferenceopt.png" class="paper-img" width="100%" height="100%"
                    alt="Active Preference Optimization for Sample Efficient RLHF" focusable="false" loading="lazy" /></a>
            
        </div>
        <div class="col col-12 col-md-8 col-xl-9 d-flex align-items-center">
            <div class="paper-body">
                <a href="https://arxiv.org/abs/2402.10500">
                    <h3 class="paper-title hover-underline-animation">Active Preference Optimization for Sample Efficient RLHF</h3>
                </a>
                <p class="paper-authors">Nirjhar Das, Souradip Chakraborty, Aldo Pacchiano, Sayak Ray Chowdhury</p>
                <p class="paper-venue">ArXiv</p>
                
                
            </div>
        </div>
    </div>
    
</div>

            
                <div class="card border-0 m-4 slide-fade-in" data-topics="[Reinforcement Learning RLHF]">
    <div class="row row-cols-1 row-cols-md-2 d-flex align-items-center">
        <div class="col col-12 col-md-4 col-xl-3">
            
            <a href="https://arxiv.org/abs/2402.03282"><img src="porrl.png" class="paper-img" width="100%" height="100%"
                    alt="A Theoretical Framework for Partially-Observed Reward States in RLHF" focusable="false" loading="lazy" /></a>
            
        </div>
        <div class="col col-12 col-md-8 col-xl-9 d-flex align-items-center">
            <div class="paper-body">
                <a href="https://arxiv.org/abs/2402.03282">
                    <h3 class="paper-title hover-underline-animation">A Theoretical Framework for Partially-Observed Reward States in RLHF</h3>
                </a>
                <p class="paper-authors">Chinmaya Kausik, Mirco Mutti, Aldo Pacchiano, Ambuj Tewari</p>
                <p class="paper-venue">ICLR 2025</p>
                
                
            </div>
        </div>
    </div>
    
</div>

            
                <div class="card border-0 m-4 slide-fade-in" data-topics="[Reinforcement Learning Statistical Learning Theory]">
    <div class="row row-cols-1 row-cols-md-2 d-flex align-items-center">
        <div class="col col-12 col-md-4 col-xl-3">
            
            <a href="https://arxiv.org/abs/2404.09123"><img src="loril.png" class="paper-img" width="100%" height="100%"
                    alt="Provable Interactive Learning with Hindsight Instruction Feedback" focusable="false" loading="lazy" /></a>
            
        </div>
        <div class="col col-12 col-md-8 col-xl-9 d-flex align-items-center">
            <div class="paper-body">
                <a href="https://arxiv.org/abs/2404.09123">
                    <h3 class="paper-title hover-underline-animation">Provable Interactive Learning with Hindsight Instruction Feedback</h3>
                </a>
                <p class="paper-authors">Dipendra Misra, Aldo Pacchiano, Robert E Schapire</p>
                <p class="paper-venue">ICML 2024</p>
                
                
            </div>
        </div>
    </div>
    
</div>

            
                <div class="card border-0 m-4 slide-fade-in" data-topics="[Reinforcement Learning]">
    <div class="row row-cols-1 row-cols-md-2 d-flex align-items-center">
        <div class="col col-12 col-md-4 col-xl-3">
            
            <a href="https://arxiv.org/abs/2404.00195"><img src="caesar.png" class="paper-img" width="100%" height="100%"
                    alt="Multiple-policy Evaluation via Density Estimation" focusable="false" loading="lazy" /></a>
            
        </div>
        <div class="col col-12 col-md-8 col-xl-9 d-flex align-items-center">
            <div class="paper-body">
                <a href="https://arxiv.org/abs/2404.00195">
                    <h3 class="paper-title hover-underline-animation">Multiple-policy Evaluation via Density Estimation</h3>
                </a>
                <p class="paper-authors">Yilei Chen, Aldo Pacchiano, Ioannis Ch. Paschalidis</p>
                <p class="paper-venue">ArXiv</p>
                
                
            </div>
        </div>
    </div>
    
</div>

            
                <div class="card border-0 m-4 slide-fade-in" data-topics="[Bandits]">
    <div class="row row-cols-1 row-cols-md-2 d-flex align-items-center">
        <div class="col col-12 col-md-4 col-xl-3">
            
            <a href="https://arxiv.org/abs/2306.02869"><img src="datadrivenbalancing.png" class="paper-img" width="100%" height="100%"
                    alt="Data-Driven Regret Balancing for Online Model Selection in Bandits" focusable="false" loading="lazy" /></a>
            
        </div>
        <div class="col col-12 col-md-8 col-xl-9 d-flex align-items-center">
            <div class="paper-body">
                <a href="https://arxiv.org/abs/2306.02869">
                    <h3 class="paper-title hover-underline-animation">Data-Driven Regret Balancing for Online Model Selection in Bandits</h3>
                </a>
                <p class="paper-authors">Aldo Pacchiano, Christoph Dann, Claudio Gentile</p>
                <p class="paper-venue">AISTATS 2024</p>
                
                
            </div>
        </div>
    </div>
    
</div>

            
                <div class="card border-0 m-4 slide-fade-in" data-topics="[Bandits]">
    <div class="row row-cols-1 row-cols-md-2 d-flex align-items-center">
        <div class="col col-12 col-md-4 col-xl-3">
            
            <a href="https://arxiv.org/abs/2401.08016"><img src="contextualbanditsconstraints.png" class="paper-img" width="100%" height="100%"
                    alt="Contextual Bandits with Stage-wise Constraints" focusable="false" loading="lazy" /></a>
            
        </div>
        <div class="col col-12 col-md-8 col-xl-9 d-flex align-items-center">
            <div class="paper-body">
                <a href="https://arxiv.org/abs/2401.08016">
                    <h3 class="paper-title hover-underline-animation">Contextual Bandits with Stage-wise Constraints</h3>
                </a>
                <p class="paper-authors">Aldo Pacchiano, Mohammad Ghavamzadeh, Peter Bartlett</p>
                <p class="paper-venue">ArXiv</p>
                
                
            </div>
        </div>
    </div>
    
</div>

            
                <div class="card border-0 m-4 slide-fade-in" data-topics="[Statistical Learning Theory]">
    <div class="row row-cols-1 row-cols-md-2 d-flex align-items-center">
        <div class="col col-12 col-md-4 col-xl-3">
            
            <a href="https://arxiv.org/abs/2306.06184"><img src="dissimilarity.png" class="paper-img" width="100%" height="100%"
                    alt="A Unified Model and Dimension for Interactive Estimation" focusable="false" loading="lazy" /></a>
            
        </div>
        <div class="col col-12 col-md-8 col-xl-9 d-flex align-items-center">
            <div class="paper-body">
                <a href="https://arxiv.org/abs/2306.06184">
                    <h3 class="paper-title hover-underline-animation">A Unified Model and Dimension for Interactive Estimation</h3>
                </a>
                <p class="paper-authors">Nataly Brukhim, Aldo Pacchiano, Miroslav Dudik, Robert Schapire</p>
                <p class="paper-venue">NeuRIPS 2023</p>
                
                
            </div>
        </div>
    </div>
    
</div>

            
                <div class="card border-0 m-4 slide-fade-in" data-topics="[Model Selection Bandits]">
    <div class="row row-cols-1 row-cols-md-2 d-flex align-items-center">
        <div class="col col-12 col-md-4 col-xl-3">
            
            <a href="https://arxiv.org/abs/2307.12897"><img src="modsellog.png" class="paper-img" width="100%" height="100%"
                    alt="Anytime Model Selection in Linear Bandits" focusable="false" loading="lazy" /></a>
            
        </div>
        <div class="col col-12 col-md-8 col-xl-9 d-flex align-items-center">
            <div class="paper-body">
                <a href="https://arxiv.org/abs/2307.12897">
                    <h3 class="paper-title hover-underline-animation">Anytime Model Selection in Linear Bandits</h3>
                </a>
                <p class="paper-authors">Parnian Kassraie, Aldo Pacchiano, Nicolas Emmenegger, Andreas Krause</p>
                <p class="paper-venue">NeuRIPS 2023</p>
                
                
            </div>
        </div>
    </div>
    
</div>

            
                <div class="card border-0 m-4 slide-fade-in" data-topics="[Statistical Learning Theory Bandits]">
    <div class="row row-cols-1 row-cols-md-2 d-flex align-items-center">
        <div class="col col-12 col-md-4 col-xl-3">
            
            <a href="https://arxiv.org/abs/2401.05193"><img src="explan.png" class="paper-img" width="100%" height="100%"
                    alt="Experiment Planning with Function Approximation" focusable="false" loading="lazy" /></a>
            
        </div>
        <div class="col col-12 col-md-8 col-xl-9 d-flex align-items-center">
            <div class="paper-body">
                <a href="https://arxiv.org/abs/2401.05193">
                    <h3 class="paper-title hover-underline-animation">Experiment Planning with Function Approximation</h3>
                </a>
                <p class="paper-authors">Aldo Pacchiano, Jonathan Lee, Emma Brunskill</p>
                <p class="paper-venue">NeuRIPS 2023</p>
                
                
            </div>
        </div>
    </div>
    
</div>

            
                <div class="card border-0 m-4 slide-fade-in" data-topics="[Reinforcement Learning]">
    <div class="row row-cols-1 row-cols-md-2 d-flex align-items-center">
        <div class="col col-12 col-md-4 col-xl-3">
            
            <a href="https://arxiv.org/abs/2306.14892"><img src="dpt.png" class="paper-img" width="100%" height="100%"
                    alt="Supervised Pretraining Can Learn In-Context Reinforcement Learning" focusable="false" loading="lazy" /></a>
            
        </div>
        <div class="col col-12 col-md-8 col-xl-9 d-flex align-items-center">
            <div class="paper-body">
                <a href="https://arxiv.org/abs/2306.14892">
                    <h3 class="paper-title hover-underline-animation">Supervised Pretraining Can Learn In-Context Reinforcement Learning</h3>
                </a>
                <p class="paper-authors">Jonathan Lee, Annie Xie, Aldo Pacchiano, Yash Chandak, Chelsea Finn, Ofir Nachum, Emma Brunskill</p>
                <p class="paper-venue">NeuRIPS 2023</p>
                
                
            </div>
        </div>
    </div>
    
</div>

            
        </div>
    </div>
</div>

        </div>
    </main>
    <footer class="footer mt-auto py-3 bg-light">
    <div class="container-md d-flex flex-row justify-content-between">
        <span class="text-muted align-self-center">&copy PLAIA 2025. All rights reserved.</span>
        
            <a href="https://twitter.com/aldopacchiano"><i class="fa-brands fa-twitter footer-icon"></i></a>
        
    </div>
</footer>

    

<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>



<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"
    integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p"
    crossorigin="anonymous"></script>

    
    
    <script src="/js/paper-filter.js"></script>

</body>
</html>
